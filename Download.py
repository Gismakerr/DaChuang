import os
import earthaccess
import geopandas as gpd
from pathlib import Path
# def search_swot_data(start_date, end_date, shapefile_path=None, 
#                      granule_pattern=None, 
#                      short_name=None):
#     """
#     æŸ¥è¯¢ SWOT æ•°æ®ï¼ˆå¯é€‰ shapefile ç©ºé—´è¿‡æ»¤ï¼‰ï¼Œä¸æ‰§è¡Œä¸‹è½½ã€‚
    
#     å‚æ•°ï¼š
#     - start_date, end_date: strï¼Œæ—¶é—´èŒƒå›´ï¼ˆæ ¼å¼ 'YYYY-MM-DD'ï¼‰
#     - shapefile_path: str or Noneï¼Œshapefile è·¯å¾„ï¼ˆå¯é€‰ï¼‰
#     - granule_pattern: strï¼Œé€šé…ç¬¦åŒ¹é… granule_name
#     - short_name: strï¼Œäº§å“åç§°
    
#     è¿”å›ï¼š
#     - results: list of granules
#     """
#     bbox_filter = None

#     if shapefile_path:
#         print(f"ğŸ“ Using shapefile for spatial filter: {shapefile_path}")
#         gdf = gpd.read_file(shapefile_path)
#         bounds = gdf.total_bounds  # [minx, miny, maxx, maxy]
#         minx, miny, maxx, maxy = bounds 
#         bbox_filter = (float(minx), float(miny), float(maxx), float(maxy))
#         print(f"ğŸ—ºï¸  Bounding box: {bbox_filter}")
#         results = earthaccess.search_data(
#         short_name=short_name,
#         temporal=(f"{start_date} 00:00:00", f"{end_date} 23:59:59"),
#         bounding_box=bbox_filter,  # âœ… ç”¨ bbox è€Œä¸æ˜¯ bounding_box é¿å¼€å†²çª
#         granule_name=granule_pattern
#     )

#     else:
#         print("ğŸ“ No shapefile provided. Skipping spatial filter.")
#         results = earthaccess.search_data(
#         short_name=short_name,
#         temporal=(f"{start_date} 00:00:00", f"{end_date} 23:59:59"),
#         granule_name=granule_pattern,
#     )

#     print(f"ğŸ” Searching data from {start_date} to {end_date}...")
#     total_files = len(results)
#     total_size = sum(float(r.size()) for r in results if hasattr(r, "size"))

#     print(f"âœ… Found {total_files} matching files.")
#     print(f"ğŸ“¦ Estimated total size: {total_size:.2f} MB")

#     return results

def search_swot_data(start_date, end_date, shapefile_path=None, 
                     granule_pattern=None, 
                     short_name=None):
    """
    æŸ¥è¯¢ SWOT æ•°æ®ï¼ˆå¯é€‰ shapefile ç©ºé—´è¿‡æ»¤ï¼‰ï¼Œä¸æ‰§è¡Œä¸‹è½½ã€‚

    å‚æ•°ï¼š
    - start_date, end_date: strï¼Œæ—¶é—´èŒƒå›´ï¼ˆæ ¼å¼ 'YYYY-MM-DD'ï¼‰
    - shapefile_path: str or Noneï¼Œshapefile è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    - granule_pattern: str or Noneï¼Œé€šé…ç¬¦åŒ¹é… granule_nameï¼ˆå¯é€‰ï¼‰
    - short_name: strï¼Œäº§å“åç§°

    è¿”å›ï¼š
    - results: list of granules
    """
    bbox_filter = None

    if shapefile_path:
        print(f"ğŸ“ Using shapefile for spatial filter: {shapefile_path}")
        gdf = gpd.read_file(shapefile_path)
        bounds = gdf.total_bounds  # [minx, miny, maxx, maxy]
        minx, miny, maxx, maxy = bounds 
        bbox_filter = (float(minx), float(miny), float(maxx), float(maxy))
        print(f"ğŸ—ºï¸  Bounding box: {bbox_filter}")
    else:
        print("ğŸ“ No shapefile provided. Skipping spatial filter.")

    # æ„é€ é€šç”¨çš„æœç´¢å‚æ•°å­—å…¸
    search_kwargs = {
        "short_name": short_name,
        "temporal": (f"{start_date} 00:00:00", f"{end_date} 23:59:59"),
    }

    if bbox_filter:
        search_kwargs["bounding_box"] = bbox_filter
    if granule_pattern:
        search_kwargs["granule_name"] = granule_pattern

    print(f"ğŸ” Searching data from {start_date} to {end_date}...")

    results = earthaccess.search_data(**search_kwargs)

    total_files = len(results)
    total_size = sum(float(r.size()) for r in results if hasattr(r, "size"))

    print(f"âœ… Found {total_files} matching files.")
    print(f"ğŸ“¦ Estimated total size: {total_size:.2f} MB")

    return results


# def download_swot_granules(results, download_dir):
#     """
#     ä¸‹è½½ SWOT granules åˆ°æŒ‡å®šç›®å½•ï¼Œè‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨ä¸”å¤§å°ä¸€è‡´çš„æ–‡ä»¶ã€‚
#     """

#     os.makedirs(download_dir, exist_ok=True)
#     to_download = []
#     skipped = 0

#     print(f"\nâ¬‡ï¸ Preparing download to: {download_dir}")
    
#     for granule in results:
#         url = granule.data_links()[0]
#         filename = url.split("/")[-1]
#         filepath = Path(download_dir) / filename

#         try:
#             remote_size = float(granule.size())
#         except:
#             remote_size = None

#         if filepath.exists() and remote_size is not None:
#             local_size = filepath.stat().st_size / (1024 * 1024)  # MB
#             if abs(local_size - remote_size) < 1:
#                 print(f"âœ… Skipped (already downloaded): {filename}")
#                 skipped += 1
#                 continue

#         to_download.append(granule)

#     # æ‰¹é‡ç»Ÿä¸€ä¸‹è½½
#     print(f"\nâ¬‡ï¸ Downloading {len(to_download)} new files...")
#     downloaded_files = earthaccess.download(to_download, download_dir)

#     print("\nğŸ“Š Summary:")
#     print(f"ğŸ”¢ Total granules in search: {len(results)}")
#     print(f"âœ… Skipped (already downloaded): {skipped}")
#     print(f"â¬‡ï¸ Newly downloaded: {len(downloaded_files)}")

#     return downloaded_files

def download_swot_granules(results, download_dir):
    """
    ä¸‹è½½ SWOT granules åˆ°æŒ‡å®šç›®å½•ï¼Œ
    è‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨ä¸”å¤§å°ä¸€è‡´çš„æ–‡ä»¶ï¼›
    å¦‚æœå·²å­˜åœ¨ä½†å¤§å°ä¸ä¸€è‡´ï¼Œå…ˆåˆ é™¤å†é‡æ–°ä¸‹è½½ã€‚
    """

    os.makedirs(download_dir, exist_ok=True)
    to_download = []
    skipped = 0
    removed = 0

    print(f"\nâ¬‡ï¸ Preparing download to: {download_dir}")
    
    for granule in results:
        url = granule.data_links()[0]
        filename = url.split("/")[-1]
        filepath = Path(download_dir) / filename

        try:
            remote_size = float(granule.size())  # å•ä½ MB
        except:
            remote_size = None

        if filepath.exists() and remote_size is not None:
            local_size = filepath.stat().st_size / (1024 * 1024)  # MB
            if abs(local_size - remote_size) < 1:
                print(f"âœ… Skipped (already downloaded): {filename}")
                skipped += 1
                continue
            else:
                print(f"âš ï¸ Size mismatch, removing corrupted file: {filename}")
                filepath.unlink()  # åˆ é™¤åæ–‡ä»¶
                removed += 1
                to_download.append(granule)
        else:
            to_download.append(granule)

    # æ‰¹é‡ä¸‹è½½
    print(f"\nâ¬‡ï¸ Downloading {len(to_download)} new files...")
    downloaded_files = earthaccess.download(to_download, download_dir)

    # æ€»ç»“
    print("\nğŸ“Š Summary:")
    print(f"ğŸ”¢ Total granules in search: {len(results)}")
    print(f"âœ… Skipped (already downloaded): {skipped}")
    print(f"ğŸ—‘ï¸ Removed corrupted files: {removed}")
    print(f"â¬‡ï¸ Newly downloaded: {len(downloaded_files)}")

    return downloaded_files
